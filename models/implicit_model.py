import torch
import trimesh
from tqdm import tqdm
import time
 
from utils.common import rigid_landmark_alignment, scale_to_unit_cube 
from utils.eval import make_grid_points, reconstruct_mesh


class ImplicitShapeModel:
    def __init__(self, cfg_file = './configs/local_ensembled_deep_sdf_576.yaml', ckpt_file = './checkpoints/lirbsm_576.pth', 
                 device = 'cuda', voxel_resolution = 256, chunk_size = 100_000):
        self.device = device
        self.voxel_resolution = voxel_resolution
    
        from utils.io import read_config
        from utils.setup_model import make_model
        
        ckpt = torch.load(ckpt_file)
        cfg = read_config(cfg_file)
        
        self.model = make_model(cfg, checkpoint = ckpt['model_state_dict']) 
        self.model = self.model.to(self.device)  

        grid_points = make_grid_points(self.voxel_resolution).repeat(1, 1, 1).to(self.device) 
        self.chunks = torch.split(grid_points, chunk_size, dim = 1)

        self.latent_mean = ckpt['latent_mean']
        self.latent_std = ckpt['latent_std']
        self.latent_dim = self.latent_mean.shape[0] 

        self.model_landmarks = torch.load('artifacts/average_anchors.pt')
        print(f'Loaded {len(self.model_landmarks)} model landmarks from artifacts/average_anchors.pt.')
 
    def _mesh_from_latent(self, latent_code, scale, return_anchors):
        '''
        Reconstructs a triangle mesh from a given latent code.
        :param latent_code: The latent code as torch.Tensor of size [latent_dim]
        :param scale: Scaling factor applied to the reconstructed mesh (no scaling if not positive)
        :param return_anchors: Whether to return the anchors (if available)
        :return: The reconstructed triangle mesh as trimesh object and the anchors
            (if return_anchors enabled and available) as torch.Tensor of size [m, 3]
        '''
        latent_code = latent_code.unsqueeze(dim = 0)

        fx_chunks = []
        for points in tqdm(self.chunks, 'Reconstruct mesh'):
            _latent_code = latent_code.unsqueeze(dim = 1).repeat(1, points.shape[1], 1).to(self.device)
            output = self.model(points, _latent_code)

            if len(output) == 2:
                fx_i, anchors = output
            else: fx_i = output; anchors = None

            fx_i = fx_i.squeeze(dim = -1).detach()
            fx_chunks.append(fx_i)
        fx = torch.cat(fx_chunks, dim = 1)
       
        fx_volume = fx.reshape(fx.shape[0], self.voxel_resolution, self.voxel_resolution, self.voxel_resolution)

        mesh = reconstruct_mesh(fx_volume[0, ...].cpu())
        trimesh_mesh = trimesh.Trimesh(vertices = mesh['vertices'], faces = mesh['faces'], vertex_normals = mesh['normals'])

        if scale > 0:
            trimesh_mesh.vertices /= scale

        if return_anchors and anchors is not None:
            return trimesh_mesh, anchors.squeeze(dim = 0).detach().cpu()
        
        return trimesh_mesh
 
    def sample(self, scale = -1, return_anchors = False):
        '''
        Randomly samples from the shape model.
        :param scale: Optional scaling factor applied to the sample (no scaling if not positive)
        :param return_anchors: Whether to return the anchors (if available) as torch.Tensor of size [m, 3]
        :return: The reconstructed triangle mesh as trimesh object
        '''
        random_latent = torch.randn(self.latent_mean.shape) * self.latent_std * 1.0 + self.latent_mean
        return self._mesh_from_latent(random_latent, scale, return_anchors)

    def mean_shape(self, scale = -1, return_anchors = False):
        '''
        Returns the mean shape of the shape model.
        :param scale: Optional scaling factor applied to the mean shape (no scaling if not positive)
        :param return_anchors: Whether to return the anchors (if available) as torch.Tensor of size [m, 3]
        :return: The reconstructed triangle mesh as trimesh object
        '''
        return self._mesh_from_latent(self.latent_mean, scale, return_anchors)  

    def reconstruct(self, point_cloud, landmarks = None, scale = -1, num_iterations = 1_000, num_samples_per_iteration = 1_000,
                    latent_weight = 0.05, anchor_weight = -1, return_anchors = False, verbose = False):
        '''
        Reconstructs a surface mesh from a given point cloud using latent code optimization.
        :param point_cloud: The input point cloud as torch.Tensor of size [n, 3]
        :param landmarks: Optinal landmarks as torch.Tensor of size [m, 3] to rigidly align
            the point cloud with the model before reconstruction
        :param scale: Optional scaling factor applied to the reconstructed mesh (no scaling if not positive)
        :param num_iterations: The number of optimization iterations
        :param num_samples_per_iteration: The number of points to subsample from the point cloud per iteration
        :param latent_weight: The weight of the latent regularization term
        :param anchor_weight: The weight of the anchor loss term (if negative, no anchor loss is used)
        :param return_anchors: Whether to return the anchors (if available) as torch.Tensor of size [m, 3]
        :param verbose: Whether to print optimization progress
        :return: The reconstructed triangle mesh as trimesh object
        '''
        if verbose: print('Scale mesh to unit cube, [-1, 1]^3.')

        # Scale point cloud to unit cube, [-1, 1]^3. Save transformation, so that we can later re-transform
        # the reconstructed mesh back to the original scale.
        point_cloud, pt_center, pt_scale = scale_to_unit_cube(point_cloud, padding = 0.1, return_transformation = True)
        point_cloud *= 2.0  
      
        if landmarks is not None:
            if verbose: print('Rigidly align point cloud with model.')  
           
            if self.model_landmarks is None:
                raise ValueError('Model landmarks are required for rigid alignment.')
            
            # Scale landmarks to unit cube, [-1, 1]^3.
            landmarks = (landmarks - pt_center) * 2.0 * pt_scale

            R, t, c = rigid_landmark_alignment(landmarks, self.model_landmarks)
            point_cloud = (point_cloud * c) @ R.T + t
            landmarks = (landmarks * c) @ R.T + t

            landmarks = landmarks.unsqueeze_(dim = 0).to(self.device)
            
        point_cloud = point_cloud.unsqueeze(dim = 0).to(self.device)

        latent_code = torch.zeros([1, 1, self.latent_dim], device = self.device, requires_grad = True)   
        optimizer = torch.optim.Adam([latent_code], lr = 1e-2)  
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 200, gamma = 0.5)  

        if verbose: print(f'Reconstruct point cloud with {point_cloud.shape[1]} points.')

        start_time = time.time()
        for i in tqdm(range(num_iterations)):
            optimizer.zero_grad()

            # Subsample point cloud to num_samples_per_iteration points.
            rand_indc = torch.randperm(point_cloud.shape[1])[:num_samples_per_iteration]
            points = point_cloud[:, rand_indc, :].float()
            _latent_code = latent_code.repeat(1, points.shape[1], 1)

            output = self.model(points, _latent_code)

            if len(output) == 2:
                pred_sdf, anchors = output
            else: pred_sdf = output; anchors = None
            
            surface_loss = torch.abs(pred_sdf)
            latent_norm = (torch.norm(latent_code, dim = -1) ** 2).mean()

            surface_loss = surface_loss[surface_loss < 0.1]
            if i > 250:
                surface_loss = surface_loss[surface_loss < 0.05]
            if i > 500:
                surface_loss = surface_loss[surface_loss < 0.0075]

            surface_loss = surface_loss.mean()

            total_loss = surface_loss + latent_weight * latent_norm

            if anchor_weight > 0:
                # Compute anchor loss if requested (and if anchors are predicted by the model).
                anchor_loss = (torch.norm(anchors - landmarks, dim = 0) ** 2).mean() if anchors is not None else 0
                total_loss += anchor_weight * anchor_loss
           
            # Adjust latent weight(s). 
            if i in [200]: 
                latent_weight /= 3.0 

            if i in [600]: 
                latent_weight /= 10.0 
             
            if verbose: 
                anchor_loss = anchor_loss.item() if anchor_weight > 0 else 0
                print(f'Iteration {i}: surface_loss={surface_loss.item():.5f}, anchor_loss={anchor_loss:.5f}, latent_norm={latent_norm.item():.5f}, ' \
                      f'total_loss={total_loss.item():.5f}, lr={scheduler.get_last_lr()[0]:.5f}')
            
            total_loss.backward()

            optimizer.step()
            scheduler.step()

        total_time = time.time() - start_time  

        if verbose: print(f'Latent code optimization took {total_time:.2f} seconds.')

        output = self._mesh_from_latent(latent_code.squeeze(), scale, return_anchors)

        if isinstance(output, trimesh.Trimesh):
            mesh = output; anchors = None
        else: mesh, anchors = output

        if landmarks is not None:   
            if verbose: print('Undo rigid alignment and re-transform to original coordinate system.')  

            if scale > 0: c = 1.0 # Don't rescale if metrical.
            mesh.vertices = (((torch.from_numpy(mesh.vertices) - t) @ R) / c).numpy()
   
        if verbose: print('Re-transform mesh to original scale.')

        # Re-transform mesh to original scale.
        if scale <= 0: mesh.vertices /= (2.0 * pt_scale.numpy()) # Don't rescale if metrical.
        mesh.vertices += pt_center.numpy()

        if return_anchors and anchors is not None:
            return mesh, anchors
        
        return mesh
    
    def latent_space_interpolation(self, num_steps = 10, start_lat = None, end_lat = None):
        '''
        Linearly interpolates between two given latent codes, or alternatively
        between two random latent codes.
        :param num_steps: The number of interpolation steps
        :param start_lat: The starting latent code as torch.Tensor of size [latent_dim]
            (if None, a random latent code is sampled)
        :param end_lat: The ending latent code as torch.Tensor of size [latent_dim]
            (if None, a random latent code is sampled)
        :return: The interpolated triangle meshes as list of trimesh objects
        '''
        if start_lat is None and end_lat is None:
            start_lat = torch.randn(self.latent_mean.shape) * self.latent_std * 1.0 + self.latent_mean
            end_lat = torch.randn(self.latent_mean.shape) * self.latent_std * 1.0 + self.latent_mean

        meshes = []
        for t in range(num_steps):
            alpha = t / (num_steps - 1)
            interpolated_lat = (1 - alpha) * start_lat + alpha * end_lat
            meshes.append(self._mesh_from_latent(interpolated_lat, scale = -1, return_anchors = False))
       
        return meshes